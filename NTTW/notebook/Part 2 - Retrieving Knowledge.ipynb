{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import torch\n",
    "import GPUtil\n",
    "import warnings\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from torch import cuda, bfloat16\n",
    "from huggingface_hub import HfApi\n",
    "from chromadb.config import Settings\n",
    "from IPython.display import display, HTML\n",
    "from huggingface_hub import login as hf_login\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.util import pytorch_cos_sim\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer, util\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoTokenizer, AutoProcessor, BitsAndBytesConfig, pipeline\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: c:\\Diego\\5. Proyectos\\Language Models\\1. LLM learning from YouTube\n"
     ]
    }
   ],
   "source": [
    "path = os.path.dirname(os.getcwd())\n",
    "os.chdir(path)\n",
    "print(f'path: {path}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leveraging GPU for Perfomance \n",
    "To optimize performance, we'll use GPU accelaration if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU name: NVIDIA GeForce RTX 4090 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing the Vector Database\n",
    "First, we'll access our previously created Chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DB from disk\n",
    "client = chromadb.PersistentClient(\n",
    "    path='data/vectordb'\n",
    "    )\n",
    "collection = client.get_collection(\n",
    "    name='youtube_knowledgebase'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "1. Secret Teachings of Plato & Theology of Arithmetic - Pythagorean Origins of Sacred Geometry\n",
      "2. The Nazi Quest To Find The Holy Grail | Myth Hunters\n",
      "3. The Occult Philosophy of Cornelius Agrippa - 1 of X - Life and Works\n",
      "4. The Real Assassin's Creed: Deadliest Special Forces Of The Dark Ages | Ancient Black Ops | Chronicle\n",
      "5. The Testament of Solomon - The Origins of Solomonic Magic, Occultism & Demonology\n",
      "6. What is Hermeticism?\n",
      "7. Who is Metatron? The Origins of the Angel from the 3rd Book of Enoch - Sefer Hekhalot Mysticism\n",
      "8. Who is Set - The Egyptian God of the Desert, Violence & Foreigners\n",
      "9. Who is Thoth?  The Egyptian God of Writing, Magic, the Moon and Fate who Became Hermes Trismegistus\n",
      "10. Who is Yahweh - How a Warrior-Storm God became the God of the Israelites and World Monotheism\n"
     ]
    }
   ],
   "source": [
    "# query the available titles in the collection\n",
    "titles_list = np.unique([col['title'] for col in collection.get()['metadatas']])\n",
    "print('-------------------------------------------------------------')\n",
    "for idx, title in enumerate(titles_list,start=1):\n",
    "    print(f'{idx}. {title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up the Language Model\n",
    "For the generation part of RAG, we'll use a large language model. In this case, we're using Mistral-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecb5178e10949eb99cc4b5a66da13ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize Mistral model\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# set quantization configuration\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# load the Mistral model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "# create a pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=4000,\n",
    "    temperature=0.6, # Higher values (e.g., 1.0) make output more random, lower values (e.g., 0.1) make it more deterministic.\n",
    "    top_p=0.9 # The model considers the smallest set of tokens whose cumulative probability exceeds this value.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "GPU Load: 1.00%\n",
      "GPU Free Memory: 11.55GB\n",
      "GPU Used Memory: 4.12GB\n",
      "GPU Total Memory: 15.99GB\n",
      "GPU Temperature: 42.00 Â°C\n",
      "GPU UUID: GPU-485b456e-7834-020d-296e-c970b89f2e0f\n"
     ]
    }
   ],
   "source": [
    "print_gpu_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the Overall Structure of the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving transcript\n",
    "title = 'What is Hermeticism?'\n",
    "flag = [col['title']==title for col in collection.get()['metadatas']]\n",
    "documents = pd.DataFrame(collection.get()['documents'],columns=['documents'])\n",
    "documents = documents[flag].reset_index(drop=True) \n",
    "documents = documents['documents'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections and subsections prompt\n",
    "context = ' '.join(documents)\n",
    "prompt = f\"\"\"\n",
    "Summarize the following text about '{title}'. \n",
    "Divide your summary into 3-5 main sections or topics. For each section:\n",
    "1. Provide a brief title.\n",
    "2. Write a 100 words explanation of the main key points discussed in that section.\n",
    "\n",
    "Text to summarize:\n",
    "---------------------\n",
    "<chunk>\n",
    "{context}\n",
    "</chunk>\n",
    "---------------------\n",
    "\n",
    "Summary:\n",
    "\"\"\"    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = pipe(prompt, \n",
    "                max_new_tokens=len(prompt)+2000,\n",
    "                truncation=True)\n",
    "response = response[0]['generated_text']\n",
    "summary = response.split(\"Summary:\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarization prompt\n",
    "fin_prompt = f\"\"\"\n",
    "Summarize the following text about '{title}'. It should look like an abstract, rember to look at the text structure to not forget any detail for the global summary.\n",
    "The global summary should not have more than 500 words. \n",
    "\n",
    "Text structure:\n",
    "---------------------\n",
    "<structure>\n",
    "{summary}\n",
    "</structure>\n",
    "---------------------\n",
    "\n",
    "Text to summarize:\n",
    "---------------------\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "---------------------\n",
    "\n",
    "Summary:\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = pipe(fin_prompt, \n",
    "                max_new_tokens=len(prompt)+2000,\n",
    "                truncation=True)\n",
    "response = response[0]['generated_text']\n",
    "fin_summary = response.split(\"Summary:\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"overflow:auto; border:1px solid #ddd; padding:20px; font-family: Arial, sans-serif; line-height: 1.6;\">\n",
       "    \n",
       "<h2 style=\"color: #FF0000;\">YouTube Video:</h2>\n",
       "<p>What is Hermeticism?</p>\n",
       "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
       "\n",
       "<h2 style=\"color: #4a86e8;\">Final Summary:</h2>\n",
       "<p>Hermeticism is a mystical and philosophical movement that originated in late antiquity in a Greco-Egyptian environment. The central figure of this movement is Hermes Tris Megista, an elusive deity with various legends and myths associated with him. Hermes is often merged with the Egyptian god Toth, who served as a messenger of the gods and was associated with writing and wisdom. The technical and philosophical Hermeticica are two categories of texts attributed to Hermes, with the former focusing on occult sciences like magic and astrology, and the latter being more speculative and philosophical in nature. The Corpus Hermeticum is the most famous collection of Hermetic texts, consisting of 18 treatises that discuss the individual soul's potential ascent to the world of the divine. Despite being edited by later scholars, these texts still provide significant insights into the cosmos and its relationship to God.</p>\n",
       "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
       "\n",
       "<h2 style=\"color: #6aa84f;\">Detailed Summary:</h2>\n",
       "<p>I. Introduction to Hermeticism<br>A. Definition of Hermeticism<br>B. Importance of Hermeticism<br>C. Brief History of Hermeticism<br><br>II. The Central Figure of Hermeticism: Hermes Tris Megista<br>A. Elusive Nature of Hermes<br>B. Different Legends and Myths about Hermes<br>C. Human Background of Hermes<br>D. Divine Nature of Hermes<br><br>III. The Merging of Greek and Egyptian Gods: Toth and Hermes<br>A. Toth: God of Writing and Wisdom<br>B. Hermes: God of Threshold and Border Crossing<br>C. Merging of Toth and Hermes<br><br>IV. The Technical and Philosophical Hermeticica<br>A. Technical Hermeticica<br>B. Philosophical Hermeticica<br>C. Dating of Hermeticica<br><br>V. The Corpus Hermeticum<br>A. Overview of the Corpus Hermeticum<br>B. Importance of the Corpus Hermeticum<br>C. Editing of the Corpus Hermeticum<br><br>VI. Conclusion<br>A. Recap of Key Points<br>B. Future Directions for Research<br>C. Final Thoughts on Hermeticism</p>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summ = '<br>'.join(summary.split('\\n'))\n",
    "\n",
    "long_text = f'''\n",
    "<h2 style=\"color: #FF0000;\">YouTube Video:</h2>\n",
    "<p>{title}</p>\n",
    "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
    "\n",
    "<h2 style=\"color: #4a86e8;\">Final Summary:</h2>\n",
    "<p>{fin_summary}</p>\n",
    "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
    "\n",
    "<h2 style=\"color: #6aa84f;\">Detailed Summary:</h2>\n",
    "<p>{summ}</p>\n",
    "'''\n",
    "\n",
    "html_code = f'''\n",
    "<div style=\"overflow:auto; border:1px solid #ddd; padding:20px; font-family: Arial, sans-serif; line-height: 1.6;\">\n",
    "    {long_text}\n",
    "</div>\n",
    "'''\n",
    "\n",
    "display(HTML(html_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q&A our Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query \n",
    "query = 'Tell me more about the merging of Toth and Hermes'\n",
    "results = collection.query(query_texts=query, n_results=20)\n",
    "df = pd.DataFrame({\n",
    "            'id':results['ids'][0], \n",
    "            'score':results['distances'][0],\n",
    "            'channel':[item['channel'] for sublist in results['metadatas'] for item in sublist],\n",
    "            'title':[item['title'] for sublist in results['metadatas'] for item in sublist],\n",
    "            'content':results['documents'][0],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-ranking\n",
    "reranker = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
    "model = CrossEncoder(reranker, max_length=512)\n",
    "scores = model.predict([(query, doc) for doc in results[\"documents\"][0]])\n",
    "df['rerank'] = (scores - scores.min())/(scores.max()-scores.min())\n",
    "df['score_'] = df['rerank']*.6 + df['rerank']*.4\n",
    "df.sort_values('score_',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "sources = df.iloc[:5,[2,3]]\n",
    "sources = (sources['channel'] + ': ' + sources['title']).unique().tolist()\n",
    "sources = '<br>'.join(sources)\n",
    "context = df.iloc[:5,4]\n",
    "context = ' '.join(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = f\"\"\"\n",
    "You are a helpful and smart assistant, whose sole purpose is to answer questions related\\n\n",
    "to the user's context. If the given context is not sufficient to answer the question, you need\\n \n",
    "to reply that you can answer based on partial information. If you are answering, please provide a\\n \n",
    "detailed answer based on the context provided of at least 200 words.\\n\n",
    "Context information is below.\n",
    "---------------------\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "---------------------\n",
    "Query: {query}.\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = pipe(qa_prompt, \n",
    "                max_new_tokens=len(qa_prompt)+2000,\n",
    "                truncation=True)\n",
    "response = response[0]['generated_text']\n",
    "qa_answer = response.split(\"Answer:\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto; border:1px solid #ddd; padding:10px;\">\n",
       "<h2 style=\"color: #4a86e8;\">Query:</h3>\n",
       "<p>Tell me more about the merging of Toth and Hermes</p>\n",
       "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
       "\n",
       "<h2 style=\"color: #6aa84f;\">Answer:</h3>\n",
       "<p>The merging of Toth and Hermes is a fascinating topic in the history of ancient Egypt. Toth was the god of wisdom, writing, and magic, while Hermes was the messenger god, known for his swiftness and cunning. The two gods were often depicted together, with Toth holding a scepter and Hermes holding a staff, symbolizing their unity.\n",
       "\n",
       "The merging of Toth and Hermes can be traced back to the New Kingdom period of ancient Egypt, around 1550-1077 BCE. During this time, the worship of Toth and Hermes became more widespread, and their images were often found in temples and tombs. The two gods were seen as complementary, with Toth representing the intellectual and spiritual aspects of life, while Hermes represented the practical and physical aspects.\n",
       "\n",
       "One of the most famous examples of the merging of Toth and Hermes is the Stele of the Sphinx, which was discovered in 1817 near the Great Pyramid of Giza. The stele features a scene of Toth and Hermes standing before the Sphinx, with Toth holding a scepter and Hermes holding a staff. The inscription on the stele describes Toth as the god of wisdom and magic, while Hermes is described as the god of wisdom and the messenger of the gods.\n",
       "\n",
       "The merging of Toth and Hermes also appears in other ancient Egyptian texts and artifacts. For example, the Book of the Dead, a collection of funerary texts that were believed to guide the deceased through the afterlife, often mentions both Toth and Hermes. In one passage, Toth is described as the god of wisdom and magic, while Hermes is described as the god of wisdom and the messenger of the gods.\n",
       "\n",
       "Overall, the merging of Toth and Hermes is a testament to the rich cultural and religious diversity of ancient Egypt. The two gods were seen as complementary, representing different aspects of life and the afterlife. Their images and symbols continue to be found in Egyptian art and architecture today, reminding us of the enduring influence of this ancient civilization.</p>\n",
       "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
       "\n",
       "<h2 style=\"color: #e69138;\">Sources:</h3>\n",
       "<p>Let's Talk Religion: What is Hermeticism?<br>ESOTERICA: Who is Thoth?  The Egyptian God of Writing, Magic, the Moon and Fate who Became Hermes Trismegistus</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_text = f'''\n",
    "<h2 style=\"color: #4a86e8;\">Query:</h3>\n",
    "<p>{query}</p>\n",
    "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
    "\n",
    "<h2 style=\"color: #6aa84f;\">Answer:</h3>\n",
    "<p>{qa_answer}</p>\n",
    "<hr style=\"border-top: 2px solid #e0e0e0;\">\n",
    "\n",
    "<h2 style=\"color: #e69138;\">Sources:</h3>\n",
    "<p>{sources}</p>\n",
    "'''\n",
    "\n",
    "html_code = f'<div style=\"overflow:auto; border:1px solid #ddd; padding:10px;\">{long_text}</div>'\n",
    "display(HTML(html_code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
