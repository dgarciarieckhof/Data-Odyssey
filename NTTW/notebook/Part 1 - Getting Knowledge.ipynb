{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import spacy\n",
    "import torch\n",
    "import GPUtil\n",
    "import warnings\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers.util import pytorch_cos_sim\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer, util\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: c:\\Diego\\5. Proyectos\\Language Models\\1. LLM learning from YouTube\n"
     ]
    }
   ],
   "source": [
    "path = os.path.dirname(os.getcwd())\n",
    "os.chdir(path)\n",
    "print(f'path: {path}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leveraging GPU for Perfomance \n",
    "To optimize performance, we'll use GPU accelaration if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU name: NVIDIA GeForce RTX 4090 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up the Vector Database\n",
    "We'll use Chroma as our vector database to store and retrieve our processed video content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding model max length is: 254\n"
     ]
    }
   ],
   "source": [
    "model_name = 'all-MiniLM-L6-v2'\n",
    "encoder_model, max_seq_length, collection, client = setup_vector_db(\n",
    "    model_name=model_name,\n",
    "    path_name='./data/vectordb', \n",
    "    collection_name='youtube_knowledgebase', \n",
    "    device=device\n",
    "    )\n",
    "\n",
    "print(f'embedding model max length is: {max_seq_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Video Data\n",
    "Fetching transcripts and metada for each video id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_api_key = ''\n",
    "video_id = [\n",
    "    'qZyROOYq4LI',\n",
    "    'vsu7HW0ouVA',\n",
    "    'BBozTcgOFGc',\n",
    "    '4io43JYVpZ0',\n",
    "    '1z_9RTbbGcU',\n",
    "    'mdKst8zeh-U',\n",
    "    '1-VGkaqDxbY',\n",
    "    'CIWq_k2tiYg',\n",
    "    'zoPtrb2eMCQ',\n",
    "    'NjDq9amO-s0'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "video_data_list = get_video_data(video_id, youtube_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic Chunking\n",
    "One of the key steps in our process is semantic chunking, which helps us break down the transcript into meaningful segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385 sentences extracted from transcript\n",
      "509 sentences extracted from transcript\n",
      "173 sentences extracted from transcript\n",
      "160 sentences extracted from transcript\n",
      "170 sentences extracted from transcript\n",
      "246 sentences extracted from transcript\n",
      "161 sentences extracted from transcript\n",
      "188 sentences extracted from transcript\n",
      "190 sentences extracted from transcript\n",
      "342 sentences extracted from transcript\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "chunks_list = [semantic_chunking(video_data['transcript'], encoder_model, nlp) for video_data in video_data_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Chunks and Populating the Database\n",
    "Finally, we'll process our chunks and store them in our vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for video_data, chunks in tqdm(zip(video_data_list, chunks_list), total=len(video_data_list)):\n",
    "    processed_chunks, embeddings = process_chunks(chunks, max_seq_length, encoder_model)\n",
    "    populate_database(collection, processed_chunks, embeddings, video_data['metadata'], video_data['video_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
